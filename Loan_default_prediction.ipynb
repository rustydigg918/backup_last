{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "\n",
    "\n",
    "### Lending Club enables borrowers to create unsecured personal loans. The standard loan period is three years. Investors can search and browse the loan listings on Lending Club website and select loans that they want to invest in based on the information supplied about the borrower, amount of loan, loan grade, and loan purpose. Investors make money from interest. Lending Club makes money by charging borrowers an origination fee and investors a service fee.\n",
    "\n",
    "\n",
    "#### In this project one has to put themself in the shoes of a loan issuer and manage credit risk by using the past data and deciding whom to give the loan to in the future. The text files contain complete loan data for all loans issued by XYZ Corp. through 2007-2015. The data contains the indicator of default, payment information, credit history, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Default Prediction\n",
    "\n",
    "##### Project by <b>Pushkar Raj </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the text data\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Finale Project\\Python Project\n"
     ]
    }
   ],
   "source": [
    "# Setting the path to my local directory where my dataset is placed\n",
    "\n",
    "import os\n",
    "os.chdir('E:\\\\Finale Project\\\\Python Project')\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing,metrics \n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 11,6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 855969 entries, 0 to 855968\n",
      "Data columns (total 73 columns):\n",
      "id                             855969 non-null int64\n",
      "member_id                      855969 non-null int64\n",
      "loan_amnt                      855969 non-null float64\n",
      "funded_amnt                    855969 non-null float64\n",
      "funded_amnt_inv                855969 non-null float64\n",
      "term                           855969 non-null object\n",
      "int_rate                       855969 non-null float64\n",
      "installment                    855969 non-null float64\n",
      "grade                          855969 non-null object\n",
      "sub_grade                      855969 non-null object\n",
      "emp_title                      806526 non-null object\n",
      "emp_length                     812908 non-null object\n",
      "home_ownership                 855969 non-null object\n",
      "annual_inc                     855969 non-null float64\n",
      "verification_status            855969 non-null object\n",
      "issue_d                        855969 non-null object\n",
      "pymnt_plan                     855969 non-null object\n",
      "desc                           121812 non-null object\n",
      "purpose                        855969 non-null object\n",
      "title                          855936 non-null object\n",
      "zip_code                       855969 non-null object\n",
      "addr_state                     855969 non-null object\n",
      "dti                            855969 non-null float64\n",
      "delinq_2yrs                    855969 non-null float64\n",
      "earliest_cr_line               855969 non-null object\n",
      "inq_last_6mths                 855969 non-null float64\n",
      "mths_since_last_delinq         416157 non-null float64\n",
      "mths_since_last_record         131184 non-null float64\n",
      "open_acc                       855969 non-null float64\n",
      "pub_rec                        855969 non-null float64\n",
      "revol_bal                      855969 non-null float64\n",
      "revol_util                     855523 non-null float64\n",
      "total_acc                      855969 non-null float64\n",
      "initial_list_status            855969 non-null object\n",
      "out_prncp                      855969 non-null float64\n",
      "out_prncp_inv                  855969 non-null float64\n",
      "total_pymnt                    855969 non-null float64\n",
      "total_pymnt_inv                855969 non-null float64\n",
      "total_rec_prncp                855969 non-null float64\n",
      "total_rec_int                  855969 non-null float64\n",
      "total_rec_late_fee             855969 non-null float64\n",
      "recoveries                     855969 non-null float64\n",
      "collection_recovery_fee        855969 non-null float64\n",
      "last_pymnt_d                   847107 non-null object\n",
      "last_pymnt_amnt                855969 non-null float64\n",
      "next_pymnt_d                   602998 non-null object\n",
      "last_credit_pull_d             855919 non-null object\n",
      "collections_12_mths_ex_med     855913 non-null float64\n",
      "mths_since_last_major_derog    213139 non-null float64\n",
      "policy_code                    855969 non-null float64\n",
      "application_type               855969 non-null object\n",
      "annual_inc_joint               442 non-null float64\n",
      "dti_joint                      440 non-null float64\n",
      "verification_status_joint      442 non-null object\n",
      "acc_now_delinq                 855969 non-null float64\n",
      "tot_coll_amt                   788656 non-null float64\n",
      "tot_cur_bal                    788656 non-null float64\n",
      "open_acc_6m                    13288 non-null float64\n",
      "open_il_6m                     13288 non-null float64\n",
      "open_il_12m                    13288 non-null float64\n",
      "open_il_24m                    13288 non-null float64\n",
      "mths_since_rcnt_il             12934 non-null float64\n",
      "total_bal_il                   13288 non-null float64\n",
      "il_util                        11609 non-null float64\n",
      "open_rv_12m                    13288 non-null float64\n",
      "open_rv_24m                    13288 non-null float64\n",
      "max_bal_bc                     13288 non-null float64\n",
      "all_util                       13288 non-null float64\n",
      "total_rev_hi_lim               788656 non-null float64\n",
      "inq_fi                         13288 non-null float64\n",
      "total_cu_tl                    13288 non-null float64\n",
      "inq_last_12m                   13288 non-null float64\n",
      "default_ind                    855969 non-null int64\n",
      "dtypes: float64(49), int64(3), object(21)\n",
      "memory usage: 476.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "      <th>default_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.559690e+05</td>\n",
       "      <td>8.559690e+05</td>\n",
       "      <td>855969.000000</td>\n",
       "      <td>855969.000000</td>\n",
       "      <td>855969.000000</td>\n",
       "      <td>855969.000000</td>\n",
       "      <td>855969.000000</td>\n",
       "      <td>8.559690e+05</td>\n",
       "      <td>855969.000000</td>\n",
       "      <td>855969.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11609.000000</td>\n",
       "      <td>13288.000000</td>\n",
       "      <td>13288.000000</td>\n",
       "      <td>13288.000000</td>\n",
       "      <td>13288.000000</td>\n",
       "      <td>7.886560e+05</td>\n",
       "      <td>13288.000000</td>\n",
       "      <td>13288.000000</td>\n",
       "      <td>13288.000000</td>\n",
       "      <td>855969.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.224073e+07</td>\n",
       "      <td>3.476269e+07</td>\n",
       "      <td>14745.571335</td>\n",
       "      <td>14732.378305</td>\n",
       "      <td>14700.061226</td>\n",
       "      <td>13.192320</td>\n",
       "      <td>436.238072</td>\n",
       "      <td>7.507119e+04</td>\n",
       "      <td>18.122165</td>\n",
       "      <td>0.311621</td>\n",
       "      <td>...</td>\n",
       "      <td>71.486993</td>\n",
       "      <td>1.354305</td>\n",
       "      <td>2.945515</td>\n",
       "      <td>5840.443332</td>\n",
       "      <td>61.024526</td>\n",
       "      <td>3.216357e+04</td>\n",
       "      <td>0.947772</td>\n",
       "      <td>1.524232</td>\n",
       "      <td>1.841963</td>\n",
       "      <td>0.054286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.271969e+07</td>\n",
       "      <td>2.399418e+07</td>\n",
       "      <td>8425.340005</td>\n",
       "      <td>8419.471653</td>\n",
       "      <td>8425.805478</td>\n",
       "      <td>4.368365</td>\n",
       "      <td>243.726876</td>\n",
       "      <td>6.426447e+04</td>\n",
       "      <td>17.423629</td>\n",
       "      <td>0.857189</td>\n",
       "      <td>...</td>\n",
       "      <td>23.015293</td>\n",
       "      <td>1.483710</td>\n",
       "      <td>2.595313</td>\n",
       "      <td>5108.500262</td>\n",
       "      <td>20.018117</td>\n",
       "      <td>3.769964e+04</td>\n",
       "      <td>1.441667</td>\n",
       "      <td>2.697601</td>\n",
       "      <td>2.975049</td>\n",
       "      <td>0.226581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.473400e+04</td>\n",
       "      <td>7.069900e+04</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>15.690000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.067986e+06</td>\n",
       "      <td>1.079273e+07</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>260.550000</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>11.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2405.000000</td>\n",
       "      <td>47.900000</td>\n",
       "      <td>1.400000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.431355e+07</td>\n",
       "      <td>3.697532e+07</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>382.550000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>17.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4485.500000</td>\n",
       "      <td>62.100000</td>\n",
       "      <td>2.380000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.446311e+07</td>\n",
       "      <td>5.803559e+07</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>571.560000</td>\n",
       "      <td>9.000000e+04</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7701.250000</td>\n",
       "      <td>75.300000</td>\n",
       "      <td>3.990000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.861687e+07</td>\n",
       "      <td>7.351969e+07</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>28.990000</td>\n",
       "      <td>1445.460000</td>\n",
       "      <td>9.500000e+06</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>223.300000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>83047.000000</td>\n",
       "      <td>151.400000</td>\n",
       "      <td>9.999999e+06</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     member_id      loan_amnt    funded_amnt  \\\n",
       "count  8.559690e+05  8.559690e+05  855969.000000  855969.000000   \n",
       "mean   3.224073e+07  3.476269e+07   14745.571335   14732.378305   \n",
       "std    2.271969e+07  2.399418e+07    8425.340005    8419.471653   \n",
       "min    5.473400e+04  7.069900e+04     500.000000     500.000000   \n",
       "25%    9.067986e+06  1.079273e+07    8000.000000    8000.000000   \n",
       "50%    3.431355e+07  3.697532e+07   13000.000000   13000.000000   \n",
       "75%    5.446311e+07  5.803559e+07   20000.000000   20000.000000   \n",
       "max    6.861687e+07  7.351969e+07   35000.000000   35000.000000   \n",
       "\n",
       "       funded_amnt_inv       int_rate    installment    annual_inc  \\\n",
       "count    855969.000000  855969.000000  855969.000000  8.559690e+05   \n",
       "mean      14700.061226      13.192320     436.238072  7.507119e+04   \n",
       "std        8425.805478       4.368365     243.726876  6.426447e+04   \n",
       "min           0.000000       5.320000      15.690000  0.000000e+00   \n",
       "25%        8000.000000       9.990000     260.550000  4.500000e+04   \n",
       "50%       13000.000000      12.990000     382.550000  6.500000e+04   \n",
       "75%       20000.000000      15.990000     571.560000  9.000000e+04   \n",
       "max       35000.000000      28.990000    1445.460000  9.500000e+06   \n",
       "\n",
       "                 dti    delinq_2yrs      ...             il_util  \\\n",
       "count  855969.000000  855969.000000      ...        11609.000000   \n",
       "mean       18.122165       0.311621      ...           71.486993   \n",
       "std        17.423629       0.857189      ...           23.015293   \n",
       "min         0.000000       0.000000      ...            0.000000   \n",
       "25%        11.880000       0.000000      ...           58.500000   \n",
       "50%        17.610000       0.000000      ...           75.000000   \n",
       "75%        23.900000       0.000000      ...           87.500000   \n",
       "max      9999.000000      39.000000      ...          223.300000   \n",
       "\n",
       "        open_rv_12m   open_rv_24m    max_bal_bc      all_util  \\\n",
       "count  13288.000000  13288.000000  13288.000000  13288.000000   \n",
       "mean       1.354305      2.945515   5840.443332     61.024526   \n",
       "std        1.483710      2.595313   5108.500262     20.018117   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      1.000000   2405.000000     47.900000   \n",
       "50%        1.000000      2.000000   4485.500000     62.100000   \n",
       "75%        2.000000      4.000000   7701.250000     75.300000   \n",
       "max       22.000000     43.000000  83047.000000    151.400000   \n",
       "\n",
       "       total_rev_hi_lim        inq_fi   total_cu_tl  inq_last_12m  \\\n",
       "count      7.886560e+05  13288.000000  13288.000000  13288.000000   \n",
       "mean       3.216357e+04      0.947772      1.524232      1.841963   \n",
       "std        3.769964e+04      1.441667      2.697601      2.975049   \n",
       "min        0.000000e+00      0.000000      0.000000     -4.000000   \n",
       "25%        1.400000e+04      0.000000      0.000000      0.000000   \n",
       "50%        2.380000e+04      0.000000      0.000000      2.000000   \n",
       "75%        3.990000e+04      1.000000      2.000000      3.000000   \n",
       "max        9.999999e+06     15.000000     33.000000     32.000000   \n",
       "\n",
       "         default_ind  \n",
       "count  855969.000000  \n",
       "mean        0.054286  \n",
       "std         0.226581  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data from txt file\n",
    "data = pd.read_csv('XYZCorp_LendingData.txt',sep=\"\\t\",low_memory=False)\n",
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loan Status\n",
    "plt.figure(figsize= (12,6))\n",
    "plt.ylabel('Loan Status')\n",
    "plt.xlabel('Count')\n",
    "data['default_ind'].value_counts().plot(kind = 'barh', grid = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Purpose\n",
    "total = len(data)\n",
    "\n",
    "plt.figure(figsize = (14,6))\n",
    "\n",
    "g = sns.countplot(x=\"\", data=data, \n",
    "                  color='blue')\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "g.set_xlabel(\"Loan Status Categories\", fontsize=12)\n",
    "g.set_ylabel(\"Count\", fontsize=15)\n",
    "g.set_title(\"Loan Status Types Distribution\", fontsize=20)\n",
    "sizes=[]\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    g.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\", fontsize=12) \n",
    "g.set_ylim(0, max(sizes) * 1.10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.default_ind.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Dimension\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these features for now\n",
    "data.drop([    'id',\n",
    "             'member_id',\n",
    "             'emp_title',\n",
    "             'title',\n",
    "#              'url',\n",
    "             'zip_code',\n",
    "             'verification_status',\n",
    "             'home_ownership',\n",
    "             'issue_d',\n",
    "             'earliest_cr_line',\n",
    "             'last_pymnt_d',\n",
    "             'next_pymnt_d',\n",
    "             'desc',\n",
    "#             'pymnt_plan',\n",
    "#             'initial_list_status',\n",
    "#             'addr_state',\n",
    "             'last_credit_pull_d', \n",
    "                                    ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['verification_status_joint'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show records number\n",
    "data.count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with less than 25% data.\n",
    "lack_of_data_idx = [x for x in data.count() < 855969*0.25]\n",
    "data.drop(data.columns[lack_of_data_idx], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Deletion\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data.mths_since_last_delinq.min(), data.mths_since_last_delinq.max())\n",
    "print(data.mths_since_last_delinq.mean())\n",
    "print(data.mths_since_last_delinq.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mths_since_last_delinq = data.mths_since_last_delinq.fillna(data.mths_since_last_delinq.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Good and Bad Loan Status Ratio\n",
    "good_loan =  len(data[(data.default_ind == 0)])\n",
    "print ('Good/Bad Loan Ratio: %.2f%%'  % (good_loan/len(data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an bad/good loan indicator feature\n",
    "data['good_loan'] = np.where((data.default_ind == 0) , 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot encode some categorical features \n",
    "columns = ['term', 'grade', 'sub_grade', 'emp_length', 'purpose', 'application_type','addr_state',\n",
    "           'pymnt_plan', 'initial_list_status']\n",
    "\n",
    "for col in columns:\n",
    "    tmp_df = pd.get_dummies(data[col], prefix=col)\n",
    "    data = pd.concat((data, tmp_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop attributes that we hot-encoded\n",
    "data.drop([#'loan_status',\n",
    "           'term',\n",
    "           'grade',\n",
    "           'sub_grade',\n",
    "           'emp_length',\n",
    "           'addr_state',\n",
    "           'initial_list_status',\n",
    "           'pymnt_plan',\n",
    "           'purpose',\n",
    "           'application_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop attributes that we hot-encoded\n",
    "data.drop(['default_ind'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some features to concur w/ some algorithms\n",
    "data = data.rename(columns= {'emp_length_< 1 year':'emp_length_lt_1 year',\n",
    "                         'emp_length_n/a':'emp_length_na'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to resource limitation, we limit data to only the first 10,000 records.\n",
    "data = data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train/Test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data['good_loan']\n",
    "X = data.ix[:, data.columns != 'good_loan']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.2, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in evaluator\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Flatten Data\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "#std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "#X_train_S = std_scaler.fit_transform(X_train)\n",
    "#X_test_S = std_scaler.transform(X_test)\n",
    "\n",
    "# Use robust scaler to reduce outliers\n",
    "X_train_R = rob_scaler.fit_transform(X_train)\n",
    "X_test_R = rob_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted prediction feature\n",
    "y_0 = len(y_train[y_train == 0])/len(y_train)\n",
    "y_1 = 1 - y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(class_weight={0:y_1, 1:y_0})\n",
    "svm_clf.fit(X_train_R, y_train)\n",
    "\n",
    "svm_predictions = svm_clf.predict(X_test_R) # Save prediction\n",
    "\n",
    "\n",
    "#print(svm_clf.score(X_test_R, y_test))\n",
    "scores = cross_val_score(svm_clf, X_test_R, y_test, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\\n\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(mt.classification_report(y_test, svm_predictions))\n",
    "print(mt.confusion_matrix(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(k_neighbors=10, random_state=44, kind = 'svm')\n",
    "X_res_train, y_res_train = sm.fit_sample(X_train_R, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sm_clf = SVC()\n",
    "svm_sm_clf.fit(X_res_train, y_res_train)\n",
    "\n",
    "svm_sm_predictions = svm_clf.predict(X_test_R)\n",
    "\n",
    "#print(svm_sm_clf.score(X_test_R, y_test))\n",
    "scores = cross_val_score(svm_sm_clf, X_test_R, y_test, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\\n\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(mt.classification_report(y_test, svm_sm_predictions))\n",
    "print(mt.confusion_matrix(y_test, svm_sm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 20)\n",
    "rf.fit(X_train, y_train)\n",
    "       \n",
    "rf_predictions = rf.predict(X_test)\n",
    "\n",
    "#print(rf.score(X_test, y_test))\n",
    "scores = cross_val_score(rf, X_test, y_test, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\\n\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(mt.classification_report(y_test, rf_predictions))\n",
    "print(mt.confusion_matrix(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_predictions = xgb.predict(X_test)\n",
    "                            \n",
    "#print(xgb.score(X_test, y_test))\n",
    "scores = cross_val_score(xgb, X_test, y_test, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\\n\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(mt.classification_report(y_test, xgb_predictions))\n",
    "print(mt.confusion_matrix(y_test, xgb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another way(Re-run it again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the backup of loaded dataset\n",
    "dataset_backup=data.copy()\n",
    "dataset_backup.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing Data- It appears there are a lot of NaNs and unnecessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata = [x for x in data.count() < len(data)*0.35]\n",
    "data.drop(data.columns[missingdata], axis=1, inplace=True)\n",
    "data.shape\n",
    "data.columns\n",
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking and dropping columns with just one unique value\n",
    "unique = data.nunique()\n",
    "unique = unique[unique.values == 1]\n",
    "data.drop(labels = list(unique.index), axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "data.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['annual_inc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers Data types for numeric columns\n",
    "data['annual_inc']= data['annual_inc'].astype(float)\n",
    "data['annual_inc'].describe()\n",
    "data_fin=data.drop(data[data.annual_inc>1e+05].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketing and dropping extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin['int_rate']=data_fin['int_rate'].astype(str)\n",
    "data_fin['int_rate']= data_fin['int_rate'].map(lambda x: x.rstrip('%'))\n",
    "data_fin['int_rate']= data_fin['int_rate'].astype(float)\n",
    "data_fin['int_rate'].describe() \n",
    "buck = [0, 5, 10, 15, 20,25, 35]\n",
    "lab = ['0-5', '5-10', '10-15', '15-20', '20-25','>25']\n",
    "data_fin['int_rate_range'] = pd.cut(data_fin['int_rate'], buck, labels=lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin['loan_amnt'].describe() #0-40k\n",
    "buck = [0, 5000, 10000, 15000, 20000, 25000,40000]\n",
    "lab = ['0-5000', '5000-10000', '10000-15000', '15000-20000', '20000-25000','25000 and above']\n",
    "data_fin['loan_amnt_range'] = pd.cut(data_fin['loan_amnt'], buck, labels=lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin['annual_inc'].describe() #range 1 to 1 mill\n",
    "buck = [0, 25000, 50000, 75000, 100000,1000000]\n",
    "lab = ['0-25000', '25000-50000', '50000-75000', '75000-100000', '100000 and above']\n",
    "data_fin['annual_inc_range'] = pd.cut(data_fin['annual_inc'], buck, labels=lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic plots to understand variable distribution- Univariate and bivariate relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data_fin['loan_amnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data_fin['int_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data_fin['annual_inc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data_fin['default_ind'])\n",
    "data_fin['default_ind'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Well, Looking at this bar plot we can say this is case of class imbalance problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin['default_ind'].value_counts()/len(data_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data_fin['default_ind'])\n",
    "sns.countplot(data_fin['purpose'],hue=data_fin['default_ind'])\n",
    "sns.countplot(data_fin['purpose'],hue=data_fin['loan_amnt_range'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Home ownership variable - ANY and NONE levels do not signify anything so can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin.drop(data_fin[data_fin['home_ownership']== 'ANY'].index, inplace=True)\n",
    "data_fin.drop(data_fin[data_fin['home_ownership']== 'NONE'].index, inplace=True)\n",
    "sns.countplot(data_fin['home_ownership'],hue=data_fin['default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#employment length\n",
    "sns.countplot(data_fin['emp_length'],hue=data_fin['default_ind'])\n",
    "sns.countplot(data_fin['emp_length'],hue=data_fin['loan_amnt_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geography\n",
    "sns.countplot(data_fin['addr_state'],hue=data_fin['default_ind']) \n",
    "sns.countplot(data_fin['addr_state'],hue=data_fin['loan_amnt_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly trend\n",
    "data_fin['issue_yr']=pd.DatetimeIndex(data_fin['issue_d']).year\n",
    "data_fin['issue_mon']=pd.DatetimeIndex(data_fin['issue_d']).month\n",
    "sns.countplot(data_fin['issue_mon'],hue=data_fin['default_ind'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Checking correlation between a few key business variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_loan=data_fin[['loan_amnt','annual_inc', 'default_ind', 'int_rate', 'dti', \n",
    "               'tot_cur_bal', 'funded_amnt']]\n",
    "f, ax = plt.subplots(figsize=(16, 9))\n",
    "sns.heatmap(cor_loan.corr(), \n",
    "            xticklabels=cor_loan.columns.values,\n",
    "            yticklabels=cor_loan.columns.values,annot= True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Variable selection: Dropping retrospective variables that would not have been known at the time of loan issuance \n",
    "and thus can skew the prediction and some other unnecessary features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin.drop(['id', 'member_id','zip_code' ,'emp_title' ,'funded_amnt', 'funded_amnt_inv', 'total_pymnt', \n",
    "               'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'out_prncp','out_prncp_inv', \n",
    "               'last_pymnt_d', 'last_pymnt_amnt', 'last_credit_pull_d', 'collections_12_mths_ex_med',\n",
    "               'recoveries', 'collection_recovery_fee','title','revol_util'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping some more unnecessary features\n",
    "data_fin.drop(['next_pymnt_d', 'tot_coll_amt' , 'tot_cur_bal' ,'total_rev_hi_lim'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_fin.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For categorical variables- Hot encoding used wherever clear levels could not be established\n",
    "'emp_length'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin['emp_length'].value_counts()\n",
    "emp_range= {'< 1 year':0.5, '1 year':1, '2 years': 2, '3 years':3,\n",
    "            '4 years':4, '5 years':5,'6 years':6,'7 years':7,\n",
    "            '8 years':8,'9 years':9, '10+ years':10}\n",
    "data_fin['emplen'] = data_fin[\"emp_length\"].map(emp_range)\n",
    "data_fin['emplen'].isnull().sum() \n",
    "data_fin['emplen'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing data into categorical, continuous and count data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Categorical: 'term', 'grade', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'purpose', 'initial_list_status', 'application_type'\n",
    "\n",
    "Continuous: 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'int_rate', 'installment', 'annual_inc', 'dti', 'delinq_2yrs','open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_amnt', 'collections_12_mths_ex_med', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim'\n",
    "\n",
    "Count:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking missing values in all the columns - how many null in each column\n",
    "data_fin.isna()\n",
    "data_fin.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullseries=pd.isnull(data_fin).sum()\n",
    "nullseries[nullseries>0]\n",
    "\n",
    "data_fin['emplen'] = data_fin['emplen'].replace(np.nan, 10)\n",
    "data_fin.drop(['emp_length'],axis=1,inplace=True)\n",
    "\n",
    "data_fin['mths_since_last_delinq'] = data_fin['mths_since_last_delinq'].fillna(data_fin['mths_since_last_delinq'].median()) #mean and median v similar\n",
    "\n",
    "#very few missing values for all of them\n",
    "#data_fin['dti'] = data_fin['dti'].fillna(data_fin['dti'].mean())\n",
    "#data_fin['inq_last_6mths'] = data_fin['inq_last_6mths'].fillna(data_fin['inq_last_6mths'].mean())\n",
    "#data_fin['collections_12_mths_ex_med'] = data_fin['collections_12_mths_ex_med'].fillna(data_fin['collections_12_mths_ex_med'].mean())\n",
    "\n",
    "# A lot of NAs- with integer values so median replacement\n",
    "# NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin.isna()\n",
    "data_fin.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Feature Engineering- Encoding where not ordinality could not be established. Variables such as- verification status,subgrade, purpose,addr_state. Hot encoding needs to be done for purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_map={'Source Verified':3, 'Verified':2, 'Not Verified':1}\n",
    "data_fin['verification_status']=data_fin['verification_status'].map(verification_map)\n",
    "\n",
    "ownership_map={'MORTGAGE':1, 'RENT':2, 'OWN':3, 'OTHER':4}\n",
    "data_fin['home_ownership']=data_fin['home_ownership'].map(ownership_map)\n",
    "\n",
    "subgrade_map={'A1':1,'A2':2, 'A3':3, 'A4':4, 'A5':5, 'B1':6, 'B2':7, 'B3':8, 'B4':9, 'B5':10, \n",
    "              'C1':11, 'C2':12, 'C3':13, 'C4':14, 'C5':15, 'D1':16, 'D2':17, 'D3':18, \n",
    "              'D4':19, 'D5':20, 'E1':21, 'E2':22, 'E3':23, 'E4':24, 'E5':25, 'F1':26, \n",
    "              'F2':27, 'F3':28, 'F4':29, 'F5':30, 'G1':31, 'G2':32, 'G3':33, 'G4':34, 'G5':35}\n",
    "data_fin['sub_grade']=data_fin['sub_grade'].map(subgrade_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin= data_fin[data_fin['purpose'] != 'educational']\n",
    "data_fin= data_fin[data_fin['purpose'] !='wedding']\n",
    "data_fin= data_fin[data_fin['purpose'] !='other']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc1= pd.get_dummies(data_fin['purpose'])\n",
    "data_fin=pd.concat((data_fin,enc1), axis=1)\n",
    "data_fin.drop(['purpose'],axis=1,inplace=True)\n",
    "\n",
    "enc2= pd.get_dummies(data_fin['addr_state'])\n",
    "data_fin=pd.concat((data_fin,enc2), axis=1)\n",
    "data_fin.drop(['addr_state'],axis=1,inplace=True)\n",
    "\n",
    "enc4= pd.get_dummies(data_fin['application_type'])\n",
    "data_fin=pd.concat((data_fin,enc4), axis=1)\n",
    "data_fin.drop(['application_type'],axis=1,inplace=True)\n",
    "\n",
    "enc5= pd.get_dummies(data_fin['term'])\n",
    "data_fin=pd.concat((data_fin,enc5), axis=1)\n",
    "data_fin.drop(['term'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin.drop(['earliest_cr_line','loan_amnt_range', 'annual_inc_range','int_rate_range','grade',\n",
    "               'issue_yr','issue_mon','pymnt_plan','initial_list_status', 'total_rec_late_fee'],axis=1, inplace=True)\n",
    "data_fin.isna()\n",
    "data_fin.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_fin.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_length\n",
    "emp_length_count=data_fin['emplen'].value_counts()\n",
    "print(emp_length_count)\n",
    "bp=sns.barplot(emp_length_count.index,emp_length_count.values)\n",
    "bp.set_xticklabels(bp.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home_ownership\n",
    "home_ownership_count=data_fin['home_ownership'].value_counts()\n",
    "print(home_ownership_count)\n",
    "sns.barplot(home_ownership_count.index,home_ownership_count.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_now_delinq\n",
    "acc_now_delinq_count=data_fin['acc_now_delinq'].value_counts()\n",
    "print(acc_now_delinq_count)\n",
    "sns.barplot(acc_now_delinq_count.index,acc_now_delinq_count.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since only one class dominates so we drop this feature\n",
    "data_fin.drop(['acc_now_delinq'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual income\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(data_fin['annual_inc']);\n",
    "\n",
    "plt.subplot(122)\n",
    "data_fin['annual_inc'].plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dti\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(data_fin['dti']);\n",
    "\n",
    "plt.subplot(122)\n",
    "data_fin['dti'].plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers Treatment\n",
    "#Find mean of the column \"dti\"\n",
    "dti_mean = int(data_fin['dti'].mean())\n",
    "\n",
    "#FInd 75th Percentile of the column \"dti\"\n",
    "IQR_dti_P75 = data_fin['dti'].quantile(q=0.75)\n",
    "\n",
    "#FInd 25th Percentile of the column \"dti\"\n",
    "IQR_dti_P25 = data_fin['dti'].quantile(q=0.25)\n",
    "\n",
    "#FInd IQR of the column \"dti\"\n",
    "IQR_dti = IQR_dti_P75-IQR_dti_P25\n",
    "\n",
    "#Fix boundaries to detect outliers in column \"dti\"\n",
    "IQR_LL = int(IQR_dti_P25 - 1.5*IQR_dti)\n",
    "IQR_UL = int(IQR_dti_P75 + 1.5*IQR_dti)\n",
    "\n",
    "#treating upper end outier with mean\n",
    "data_fin.loc[data_fin['dti']>IQR_UL , 'dti'] = dti_mean\n",
    "\n",
    "#treating lower end outlier as mean\n",
    "data_fin.loc[data_fin['dti']<IQR_LL , 'dti'] = dti_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(data_fin['delinq_2yrs']);\n",
    "\n",
    "plt.subplot(122)\n",
    "data_fin['delinq_2yrs'].plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers Treatment\n",
    "#Find mean of the column \"delinq_2yrs\"\n",
    "delinq_2yrs_mean = int(data_fin['delinq_2yrs'].mean())\n",
    "\n",
    "#FInd 75th Percentile of the column \"delinq_2yrs\"\n",
    "IQR_delinq_2yrs_P75 = data_fin['delinq_2yrs'].quantile(q=0.75)\n",
    "\n",
    "#FInd 25th Percentile of the column \"delinq_2yrs\"\n",
    "IQR_delinq_2yrs_P25 = data_fin['delinq_2yrs'].quantile(q=0.25)\n",
    "\n",
    "#FInd IQR of the column \"dti\"\n",
    "IQR_delinq_2yrs = IQR_delinq_2yrs_P75-IQR_delinq_2yrs_P25\n",
    "\n",
    "#Fix boundaries to detect outliers in column \"dti\"\n",
    "IQR_LL = int(IQR_delinq_2yrs_P25 - 1.5*IQR_delinq_2yrs)\n",
    "IQR_UL = int(IQR_delinq_2yrs_P75 + 1.5*IQR_delinq_2yrs)\n",
    "\n",
    "#treating upper end outier with mean\n",
    "data_fin.loc[data_fin['delinq_2yrs']>IQR_UL , 'delinq_2yrs'] = dti_mean\n",
    "\n",
    "#treating lower end outlier as mean\n",
    "data_fin.loc[data_fin['delinq_2yrs']<IQR_LL , 'delinq_2yrs'] = dti_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_acc\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(data_fin['open_acc']);\n",
    "\n",
    "plt.subplot(122)\n",
    "data_fin['open_acc'].plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers Treatment\n",
    "#Find mean of the column \"open_acc\"\n",
    "open_acc_mean = int(data_fin['open_acc'].mean())\n",
    "\n",
    "#FInd 75th Percentile of the column \"open_acc\"\n",
    "IQR_open_acc_P75 = data_fin['open_acc'].quantile(q=0.75)\n",
    "\n",
    "#FInd 25th Percentile of the column \"open_acc\"\n",
    "IQR_open_acc_P25 = data_fin['open_acc'].quantile(q=0.25)\n",
    "\n",
    "#FInd IQR of the column \"open_acc\"\n",
    "IQR_open_acc = IQR_open_acc_P75-IQR_open_acc_P25\n",
    "\n",
    "#Fix boundaries to detect outliers in column \"open_acc\"\n",
    "IQR_LL = int(IQR_open_acc_P25 - 1.5*IQR_open_acc)\n",
    "IQR_UL = int(IQR_open_acc_P75 + 1.5*IQR_open_acc)\n",
    "\n",
    "#treating upper end outier with mean\n",
    "data_fin.loc[data_fin['open_acc']>IQR_UL , 'open_acc'] = open_acc_mean\n",
    "\n",
    "#treating lower end outlier as mean\n",
    "data_fin.loc[data_fin['open_acc']<IQR_LL , 'open_acc'] = open_acc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub_rec\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(data_fin['pub_rec']);\n",
    "\n",
    "plt.subplot(122)\n",
    "data_fin['pub_rec'].plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers Treatment\n",
    "#Find mean of the column \"pub_rec\"\n",
    "pub_rec_mean = int(data_fin['pub_rec'].mean())\n",
    "\n",
    "#FInd 75th Percentile of the column \"pub_rec\"\n",
    "IQR_pub_rec_P75 = data_fin['pub_rec'].quantile(q=0.75)\n",
    "\n",
    "#FInd 25th Percentile of the column \"pub_rec\"\n",
    "IQR_pub_rec_P25 = data_fin['pub_rec'].quantile(q=0.25)\n",
    "\n",
    "#FInd IQR of the column \"pub_rec\"\n",
    "IQR_pub_rec = IQR_pub_rec_P75-IQR_pub_rec_P25\n",
    "\n",
    "#Fix boundaries to detect outliers in column \"pub_rec\"\n",
    "IQR_LL = int(IQR_pub_rec_P25 - 1.5*IQR_pub_rec)\n",
    "IQR_UL = int(IQR_pub_rec_P75 + 1.5*IQR_pub_rec)\n",
    "\n",
    "#treating upper end outier with mean\n",
    "data_fin.loc[data_fin['pub_rec']>IQR_UL , 'pub_rec'] = pub_rec_mean\n",
    "\n",
    "#treating lower end outlier as mean\n",
    "data_fin.loc[data_fin['pub_rec']<IQR_LL , 'pub_rec'] = pub_rec_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(data_fin['revol_bal']);\n",
    "\n",
    "plt.subplot(122)\n",
    "data_fin['revol_bal'].plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers Treatment\n",
    "#Find mean of the column \"revol_bal\"\n",
    "revol_bal_mean = int(data_fin['revol_bal'].mean())\n",
    "\n",
    "#FInd 75th Percentile of the column \"revol_bal\"\n",
    "IQR_revol_bal_P75 = data_fin['revol_bal'].quantile(q=0.75)\n",
    "\n",
    "#FInd 25th Percentile of the column \"revol_bal\"\n",
    "IQR_revol_bal_P25 = data_fin['revol_bal'].quantile(q=0.25)\n",
    "\n",
    "#FInd IQR of the column \"revol_bal\"\n",
    "IQR_revol_bal = IQR_revol_bal_P75-IQR_revol_bal_P25\n",
    "\n",
    "#Fix boundaries to detect outliers in column \"revol_bal\"\n",
    "IQR_LL = int(IQR_revol_bal_P25 - 1.5*IQR_revol_bal)\n",
    "IQR_UL = int(IQR_revol_bal_P75 + 1.5*IQR_revol_bal)\n",
    "\n",
    "#treating upper end outier with mean\n",
    "data_fin.loc[data_fin['revol_bal']>IQR_UL , 'revol_bal'] = revol_bal_mean\n",
    "\n",
    "#treating lower end outlier as mean\n",
    "data_fin.loc[data_fin['revol_bal']<IQR_LL , 'revol_bal'] = revol_bal_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_acc\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(data_fin['total_acc']);\n",
    "\n",
    "plt.subplot(122)\n",
    "data_fin['total_acc'].plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers Treatment\n",
    "#Find mean of the column \"total_acc\"\n",
    "total_acc_mean = int(data_fin['total_acc'].mean())\n",
    "\n",
    "#FInd 75th Percentile of the column \"total_acc\"\n",
    "IQR_total_acc_P75 = data_fin['total_acc'].quantile(q=0.75)\n",
    "\n",
    "#FInd 25th Percentile of the column \"total_acc\"\n",
    "IQR_total_acc_P25 = data_fin['total_acc'].quantile(q=0.25)\n",
    "\n",
    "#FInd IQR of the column \"total_acc\"\n",
    "IQR_total_acc = IQR_total_acc_P75-IQR_total_acc_P25\n",
    "\n",
    "#Fix boundaries to detect outliers in column \"total_acc\"\n",
    "IQR_LL = int(IQR_total_acc_P25 - 1.5*IQR_total_acc)\n",
    "IQR_UL = int(IQR_total_acc_P75 + 1.5*IQR_total_acc)\n",
    "\n",
    "#treating upper end outier with mean\n",
    "data_fin.loc[data_fin['total_acc']>IQR_UL , 'total_acc'] = total_acc_mean\n",
    "\n",
    "#treating lower end outlier as mean\n",
    "data_fin.loc[data_fin['total_acc']<IQR_LL , 'total_acc'] = total_acc_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Multicolinearity using Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin.columns.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing Numeric and count data\n",
    "\n",
    "data_numeric=data_fin.loc[:,['loan_amnt','int_rate','sub_grade', 'home_ownership','verification_status','inq_last_6mths',\n",
    "       'annual_inc', 'dti', 'delinq_2yrs','open_acc','mths_since_last_delinq',  \n",
    "       'total_acc', 'emplen', 'revol_bal',\n",
    "       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating correlation among numeric variable \n",
    "corr_matrix = data_numeric.corr() \n",
    "\n",
    "#plot correlation matrix\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(corr_matrix,\n",
    "            cmap='coolwarm',\n",
    "            annot=True);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sampling procedures- \n",
    "1. SMOTE: can increase recall at the cost of precision \n",
    "2. Undersampling: if less data overall, minority class gets you less data \n",
    "3. ADASYN will focus on samples which are difficult to classify with NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin['issue_d'] = pd.to_datetime(data_fin['issue_d'])\n",
    "data_fin = data_fin.set_index(data_fin['issue_d'])\n",
    "data_fin = data_fin.sort_index()\n",
    "\n",
    "train = data_fin['June 2007':'May 2015']\n",
    "test  = data_fin['June 2015':'Dec 2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Dataset:',train.shape)\n",
    "print('Test Dataset:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =train.drop('issue_d' , axis=1)\n",
    "test =test.drop('issue_d', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN, RandomOverSampler, SMOTE \n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('default_ind', axis=1)\n",
    "y_train = train.loc[:,['default_ind']]\n",
    "X_test  = test.drop('default_ind', axis=1)\n",
    "y_test  = test.loc[:,['default_ind']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#OVERSAMPLING-SMOTE\n",
    "sm= SMOTE(random_state=42)\n",
    "X_sm, y_sm = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# #OVERSAMPLING-RANDOM\n",
    "# ros= RandomOverSampler(random_state=555)\n",
    "# X_over, y_over= ros.fit_sample(X_train, y_train)\n",
    "\n",
    "# #Undersampling\n",
    "# rus = RandomUnderSampler(return_indices=True, random_state=555)\n",
    "# X_resampled, y_resampled, idx_resampled= rus.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin.info()\n",
    "data_fin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std= scaler.fit_transform(X_sm)\n",
    "X_std_test= scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Logistic Regression\n",
    "\n",
    "#SMOTE\n",
    "lr_sm = LogisticRegression() \n",
    "lr_sm.fit(X_sm, y_sm)\n",
    "lr_sm.score(X_sm, y_sm)\n",
    "y_pred_sm= lr_sm.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_sm)\n",
    "roc_auc_score(y_test, y_pred_sm)\n",
    "classification_report(y_test, y_pred_sm)\n",
    "f1_score(y_test, y_pred_sm)\n",
    "\n",
    "lr_sm.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Decision Tree\n",
    "from sklearn.tree import tree, DecisionTreeClassifier\n",
    "dt = tree.DecisionTreeClassifier(criterion='gini')\n",
    "dt.fit(X_sm, y_sm)\n",
    "dt.score(X_sm, y_sm)\n",
    "y_pred_sm= dt.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_sm)\n",
    "roc_auc_score(y_test, y_pred_sm)\n",
    "classification_report(y_test, y_pred_sm)\n",
    "f1_score(y_test, y_pred_sm)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf = RandomForestClassifier(n_estimators=80, max_features= 'log2')\n",
    "rf.fit(X_sm, y_sm)\n",
    "#rf.score(X_sm, y_sm)\n",
    "y_rf= rf.predict(X_test)\n",
    "accuracy_score(y_test, y_rf)\n",
    "roc_auc_score(y_test, y_rf)\n",
    "classification_report(y_test, y_rf)\n",
    "f1_score(y_test, y_rf)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning RF\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "param_grid = { \n",
    "    'n_estimators': [20, 80],\n",
    "    'max_features': [None, 'log2', 'sqrt']\n",
    "}\n",
    "CV_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv= 5)\n",
    "CV_rf.fit(X_sm, y_sm)\n",
    "print (CV_rf.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable importance\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Trees\n",
    "from sklearn.ensemble import GradientBoostingClassifier  \n",
    "gb = GradientBoostingClassifier(n_estimators=80, learning_rate=1, \n",
    "                                random_state=42)\n",
    "gb.fit(X_sm, y_sm)\n",
    "#rf.score(X_sm, y_sm)\n",
    "y_gb= gb.predict(X_test)\n",
    "#accuracy_score(y_test, y_rf)\n",
    "roc_auc_score(y_test, y_gb)\n",
    "classification_report(y_test, y_gb)\n",
    "f1_score(y_test, y_gb) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm = svm.SVC(random_state=42, tol=100,class_weight='balanced')\n",
    "model_svm.fit(X_std, y_sm)\n",
    "y_svm= model_svm.predict(X_std_test)\n",
    "accuracy_score(y_test, y_svm)\n",
    "roc_auc_score(y_test, y_svm)\n",
    "classification_report(y_test, y_svm)\n",
    "f1_score(y_test, y_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
