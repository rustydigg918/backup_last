{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping YouTube Data using Python and Selenium to Classify Videos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "we’ll learn how to use web scraping to extract YouTube video data using Selenium and Python. \n",
    "We will then use the NLTK library to clean the data and then build a model to classify these videos based on specific categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of Selenium:\n",
    "\n",
    "\n",
    "    Selenium is a popular tool for automating browsers. It’s primarily used for testing in the industry but is also very handy for web scraping. You must have come across Selenium if you’ve worked in the IT field.\n",
    "\n",
    "We can easily program a Python script to automate a web browser using Selenium. It gives us the freedom we need to efficiently extract the data and store it in our preferred format for future use.\n",
    "\n",
    "Selenium requires a driver to interface with our chosen browser. Chrome, for example, requires ChromeDriver, which needs to be installed before we start scraping. The Selenium web driver speaks directly to the browser using the browser’s own engine to control it. This makes it incredibly fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we’ll be scraping the video ID, video title, and video description of a particular category from YouTube. The categories we’ll be scraping are:\n",
    "\n",
    "    Travel\n",
    "    Science\n",
    "    Food\n",
    "    History\n",
    "    Manufacturing\n",
    "    Art & Dance  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let’s import some libraries:\n",
    "from selenium import webdriver \n",
    "import pandas as pd \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before we do anything else, open YouTube in your browser. Type in the category you want to search videos for and set the filter to “videos”. This will display only the videos related to your search. Copy the URL after doing this.   \n",
    "\n",
    "Next, we need to set up the driver to fetch the content of the URL from YouTube:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scrapping the Travel data from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://www.youtube.com/results?search_query=Travel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "            links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a dataframe with 4 columns – “link”, “title”, “description”, and “category”. \n",
    "# We will store the details of videos for different categories in these columns:\n",
    "df = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the video details from YouTube\n",
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"df_travel\"\n",
    "for x in links:\n",
    "            driver.get(x)\n",
    "            v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "            v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "            v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "            df.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let’s breakdown this code block to understand what we just did:\n",
    "\n",
    "“wait” will ignore instances of NotFoundException that are encountered (thrown) by default in the ‘until’ condition. It will immediately propagate all others\n",
    "Parameters:\n",
    "driver: The WebDriver instance to pass to the expected conditions\n",
    "timeOutInSeconds: The timeout in seconds when an expectation is called\n",
    "v_category stores the video category name we searched for earlier\n",
    "The “for” loop is applied on the list of links we created above\n",
    "driver.get(x) traverses through all the links one-by-one and opens them in the browser to fetch the details\n",
    "v_id stores the stripped video ID from the link\n",
    "v_title stores the video title fetched by using the CSS path\n",
    "Similarly, v_description stores the video description by using the CSS path\n",
    "During each iteration, our code saves the extracted data inside the dataframe we created earlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scrapping the Science data from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://www.youtube.com/results?search_query=Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "            links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a dataframe with 4 columns – “link”, “title”, “description”, and “category”. \n",
    "# We will store the details of videos for different categories in these columns:\n",
    "df = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the video details from YouTube\n",
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"df_science\"\n",
    "for x in links:\n",
    "            driver.get(x)\n",
    "            v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "            v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "            v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "            df.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scrapping the India data from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://www.youtube.com/results?search_query=India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "            links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a dataframe with 4 columns – “link”, “title”, “description”, and “category”. \n",
    "# We will store the details of videos for different categories in these columns:\n",
    "df = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the video details from YouTube\n",
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"df_india\"\n",
    "for x in links:\n",
    "            driver.get(x)\n",
    "            v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "            v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "            v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "            df.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Scrapping the Food data from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://www.youtube.com/results?search_query=food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "            links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a dataframe with 4 columns – “link”, “title”, “description”, and “category”. \n",
    "# We will store the details of videos for different categories in these columns:\n",
    "df = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the video details from YouTube\n",
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"df_food\"\n",
    "for x in links:\n",
    "            driver.get(x)\n",
    "            v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "            v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "            v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "            df.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Scrapping the Manufacturing data from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://www.youtube.com/results?search_query=manufacturing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "            links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a dataframe with 4 columns – “link”, “title”, “description”, and “category”. \n",
    "# We will store the details of videos for different categories in these columns:\n",
    "df = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the video details from YouTube\n",
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"df_manufacturing\"\n",
    "for x in links:\n",
    "            driver.get(x)\n",
    "            v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "            v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "            v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "            df.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Scrapping the History data from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://www.youtube.com/results?search_query=history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "            links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a dataframe with 4 columns – “link”, “title”, “description”, and “category”. \n",
    "# We will store the details of videos for different categories in these columns:\n",
    "df = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the video details from YouTube\n",
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"df_history\"\n",
    "for x in links:\n",
    "            driver.get(x)\n",
    "            v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "            v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "            v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "            df.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Scrapping the Art and dance data from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://www.youtube.com/results?search_query=art+and+dance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "            links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a dataframe with 4 columns – “link”, “title”, “description”, and “category”. \n",
    "# We will store the details of videos for different categories in these columns:\n",
    "df = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the video details from YouTube\n",
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"df_artndance\"\n",
    "for x in links:\n",
    "            driver.get(x)\n",
    "            v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "            v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "            v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "            df.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_artndance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-442955326d20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_artndance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_artndance' is not defined"
     ]
    }
   ],
   "source": [
    "df_artndance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_travel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-f5ed54b34ca0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf_travel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_science\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_india\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_food\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_manufacturing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_artndance\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_axes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_travel' is not defined"
     ]
    }
   ],
   "source": [
    "frames = [df_travel, df_science, df_india, df_food, df_manufacturing, df_history, df_artndance]\n",
    "df_copy = pd.concat(frames, axis=0, join='outer', join_axes=None, ignore_index=True,keys=None, levels=None, names=None, verify_integrity=False, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
